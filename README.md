# ğŸ¤– SentinelIQ Harvester - SystÃ¨me de Veille Technique Autonome

## ğŸ¯ Vision
Un systÃ¨me de veille technique **100% autonome** qui dÃ©couvre, crawle et indexe intelligemment le contenu tech du web avec **Supabase PostgreSQL** et **recherche vectorielle**.

## âš¡ FonctionnalitÃ©s ClÃ©s

- **DÃ©couverte autonome** de nouvelles sources via moteurs de recherche
- **Crawling intelligent** avec dÃ©tection de changements
- **Anti-duplication avancÃ©e** avec hash de contenu
- **Recherche vectorielle** avec pgvector et embeddings OpenAI
- **Scaling horizontal/vertical** automatique
- **Pipeline ML** pour classification et extraction
- **API REST** haute performance avec FastAPI
- **Base Supabase** PostgreSQL cloud-native
- **Monitoring complet** avec mÃ©triques temps rÃ©el

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Discovery     â”‚    â”‚    Crawler      â”‚    â”‚   Processor     â”‚
â”‚   Engine        â”‚â”€â”€â”€â–¶â”‚   Workers       â”‚â”€â”€â”€â–¶â”‚   Pipeline      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Scheduler    â”‚    â”‚   Redis Queue   â”‚    â”‚   Supabase      â”‚
â”‚   (Celery)      â”‚    â”‚   & Cache       â”‚    â”‚   PostgreSQL    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Installation Rapide

### âš¡ Installation AutomatisÃ©e (RecommandÃ©e)

```bash
# 1. Cloner le projet
git clone <repo>
cd SentinelIQ-Harvester

# 2. Configuration environnement
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
pip install -r requirements.txt

# 3. Configuration .env
cp .env.example .env
# Ã‰ditez .env avec vos credentials Supabase

# 4. Installation complÃ¨te automatique â­
python installation/quick_start.py

# 5. DÃ©marrage
python src/main.py
```

### ï¿½ Guide d'Installation Complet

Pour une installation dÃ©taillÃ©e Ã©tape par Ã©tape, consultez le **[Guide d'Installation Complet](installation/README.md)** qui inclut :

- âœ… **Scripts d'installation automatisÃ©s**
- ğŸ”§ **Configuration Supabase dÃ©taillÃ©e** 
- ğŸ› ï¸ **DÃ©pannage et rÃ©solution d'erreurs**
- ğŸ³ **Configuration Docker et Redis**
- ğŸ“Š **VÃ©rification et tests de connexion**

### ğŸ“‹ PrÃ©requis SystÃ¨me

| Composant | Version | Statut | Notes |
|-----------|---------|---------|-------|
| **Python** | 3.11+ | âœ… Essentiel | Version recommandÃ©e |
| **Supabase** | - | âœ… Essentiel | Base de donnÃ©es cloud |
| **Docker** | Latest | âš ï¸ Optionnel | Pour Redis local |

Pour plus de dÃ©tails, consultez le **[Guide d'Installation](installation/README.md)**.

## ğŸ—„ï¸ Configuration Supabase

### Configuration Rapide
1. CrÃ©ez un projet sur [supabase.com](https://supabase.com)
2. Copiez vos credentials dans `.env`
3. Lancez `python installation/quick_start.py`

### Guide DÃ©taillÃ©
Pour une configuration complÃ¨te de Supabase avec toutes les options et le dÃ©pannage, consultez le **[Guide d'Installation DÃ©taillÃ©](installation/README.md)**.

## ğŸ“¦ DÃ©marrage

```bash
# DÃ©marrage rapide
python src/main.py

# API disponible sur
http://localhost:8000

# Documentation interactive
http://localhost:8000/docs
```

## ğŸ› ï¸ Configuration AvancÃ©e

Pour la configuration dÃ©taillÃ©e, le dÃ©pannage et les bonnes pratiques, consultez :

ğŸ“˜ **[Guide d'Installation Complet](installation/README.md)** - Configuration complÃ¨te Ã©tape par Ã©tape

Ce guide inclut :
- ğŸ—„ï¸ Configuration Supabase dÃ©taillÃ©e (credentials, extensions, poolers)
- ğŸ³ Docker et Redis (local et cloud)  
- ğŸ”§ Variables d'environnement complÃ¨tes
- ğŸš¨ DÃ©pannage des erreurs communes
- ğŸ“Š Scripts de vÃ©rification et tests

- ğŸ“Š Scripts de vÃ©rification et tests

## âš¡ Utilisation

### DÃ©marrage de l'API
```bash
python src/main.py
```

### Workers Celery (optionnel)
```bash
celery -A src.celery_app worker --loglevel=info
```

### URLs Principales
- ğŸŒ **API** : http://localhost:8000
- ğŸ“š **Documentation** : http://localhost:8000/docs
- ğŸ” **Recherche** : http://localhost:8000/search

## ğŸ—ï¸ Architecture Technique

### ï¿½ Composants Principaux

- **Discovery Engine** : DÃ©couverte autonome de nouvelles sources
- **Smart Crawler** : Crawling intelligent avec anti-duplication  
- **Content Processor** : Extraction et classification du contenu
- **Vector Search** : Recherche sÃ©mantique avec pgvector
- **API REST** : Interface haute performance avec FastAPI
- **Task Queue** : Pipeline asynchrone avec Celery

### ğŸ—„ï¸ Base de DonnÃ©es

- **Supabase PostgreSQL** : Base de donnÃ©es cloud-native
- **pgvector** : Recherche vectorielle et embeddings
- **Indexation avancÃ©e** : Performance optimisÃ©e

## ğŸ“Š MÃ©triques de Performance

- **Vitesse de crawl** : 1000+ pages/minute
- **Recherche vectorielle** : <100ms
- **DÃ©couverte quotidienne** : 100+ nouvelles sources
- **DÃ©duplication** : 99.9% de prÃ©cision
- **Uptime** : 99.9% (dÃ©pend de Supabase)

## ğŸ› ï¸ DÃ©veloppement

### Tests
```bash
pytest tests/ -v
```

### Linting et Format
```bash
black src/ tests/
flake8 src/ tests/
mypy src/
```

## ğŸŒ DÃ©ploiement

### Plateformes RecommandÃ©es
- **Railway** : DÃ©ploiement simple avec Supabase
- **Render** : Auto-deploy depuis Git
- **Fly.io** : Global edge deployment
- **Google Cloud Run** : Serverless containers

### Docker Production
```bash
docker build -t sentineliq-harvester .
docker run -d -p 8000:8000 --env-file .env sentineliq-harvester
```

```

## ï¿½ Documentation

Pour plus d'informations, consultez :

- ğŸ“˜ **[Guide d'Installation Complet](installation/README.md)** - Configuration dÃ©taillÃ©e Ã©tape par Ã©tape
- ğŸ—ï¸ **[Architecture](docs/architecture.md)** - Design et composants (Ã  venir)
- ğŸš€ **[DÃ©ploiement](docs/deployment.md)** - Guide de production (Ã  venir)
- ğŸ“¡ **[API Reference](docs/api.md)** - Endpoints et schemas (Ã  venir)

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :

- ğŸ› Signaler des bugs
- âœ¨ Proposer des amÃ©liorations  
- ğŸ“– AmÃ©liorer la documentation
- ğŸ§ª Ajouter des tests

## ğŸ”„ Roadmap

- [ ] **Q1 2025** : Interface web admin
- [ ] **Q2 2025** : Plugins d'extensions
- [ ] **Q3 2025** : ML avancÃ© (classification)
- [ ] **Q4 2025** : Multi-tenant SaaS

---

## ğŸ† DÃ©veloppÃ© par The-Genium007

**SentinelIQ Harvester** - Veille technique autonome et intelligente ğŸš€

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.11+-green.svg)](https://python.org)
[![Supabase](https://img.shields.io/badge/database-Supabase-green.svg)](https://supabase.com)
[![FastAPI](https://img.shields.io/badge/api-FastAPI-teal.svg)](https://fastapi.tiangolo.com)

### 5. ğŸ›ï¸ Types de Connexion Supabase

| Type | Usage | Avantages | Configuration |
|------|-------|-----------|---------------|
| **Direct Connection** | Apps persistantes | Connexion dÃ©diÃ©e, performances | `db.[PROJECT-ID].supabase.co:5432` |
| **Transaction Pooler** | Serverless, IPv4 | Pool partagÃ©, IPv4 compatible | `aws-0-eu-west-3.pooler.supabase.com:6543` |
| **Session Pooler** | IPv4 uniquement | Alternative au direct | `aws-0-eu-west-3.pooler.supabase.com:5432` |

## ğŸ“¦ Installation des DÃ©pendances

### DÃ©pendances Python Essentielles
```bash
pip install -r requirements.txt
```

### DÃ©pendances SystÃ¨me SupplÃ©mentaires
```bash
# Pour Supabase (dÃ©jÃ  inclus dans requirements.txt)
pip install python-dotenv psycopg2-binary

# Pour le dÃ©veloppement (optionnel)
pip install black flake8 mypy pytest
```

## ğŸ› ï¸ Scripts d'Installation

Tous les scripts sont organisÃ©s dans le dossier `installation/` :

| Script | Description | Usage |
|--------|-------------|--------|
| `check_requirements.py` | VÃ©rifie les prÃ©requis | `python installation/check_requirements.py` |
| `test_connection.py` | Test connexion Supabase | `python installation/test_connection.py` |
| `setup_supabase.py` | Configure la base | `python installation/setup_supabase.py` |

### ğŸ”„ Processus d'Installation DÃ©taillÃ©

```bash
# === 1. VÃ‰RIFICATION ===
python installation/check_requirements.py
# âœ… VÃ©rifie Python, pip, Docker, .env

# === 2. TEST CONNEXION ===  
python installation/test_connection.py
# âœ… Teste la connexion Supabase
# âœ… VÃ©rifie les extensions PostgreSQL

# === 3. CONFIGURATION BASE ===
python installation/setup_supabase.py
# âœ… CrÃ©e les tables : sources, articles, crawl_jobs
# âœ… Configure les indexes et contraintes
# âœ… Test d'insertion/lecture

# === 4. SERVICES ===
docker-compose up -d redis  # Redis local
# OU configurez Redis Cloud/Upstash

# === 5. DÃ‰MARRAGE ===
python src/main.py
```

## ï¿½ Configuration AvancÃ©e

### Variables d'Environnement ComplÃ¨tes

```bash
# === SUPABASE CONFIGURATION ===
DATABASE_URL=postgresql://postgres:password@host:port/postgres
SUPABASE_URL=https://project-id.supabase.co
SUPABASE_KEY=your-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# === REDIS CONFIGURATION ===
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2

# === API CONFIGURATION ===
API_HOST=localhost
API_PORT=8000
SECRET_KEY=your-super-secret-key
ENVIRONMENT=development

# === CRAWLER CONFIGURATION ===
CRAWLER_MAX_WORKERS=50
CRAWLER_REQUEST_TIMEOUT=30
CRAWLER_MAX_RETRIES=3
CRAWLER_DELAY_MIN=1.0
CRAWLER_DELAY_MAX=3.0

# === ML & AI CONFIGURATION ===
OPENAI_API_KEY=sk-your-openai-key
EMBEDDING_MODEL=text-embedding-ada-002
EMBEDDING_DIMENSIONS=1536

# === WORKER CONFIGURATION ===
WORKER_QUEUES=default,crawler,discovery,indexing
CELERY_WORKER_CONCURRENCY=4
CRAWL_FREQUENCY=3600  # seconds

# === MONITORING ===
LOG_LEVEL=INFO
PROMETHEUS_PORT=9090
HEALTH_CHECK_INTERVAL=30

# === DEVELOPMENT ===
DEBUG=true
TESTING=false
HOT_RELOAD=true
```

### ğŸ³ Docker Compose Services

```yaml
# docker-compose.yml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml

volumes:
  redis_data:
```

## ğŸš¨ DÃ©pannage Common Issues

### âŒ Erreur de Connexion Supabase

**ProblÃ¨me** : `nodename nor servname provided, or not known`
```bash
# Solutions par ordre de prioritÃ© :
1. VÃ©rifiez que votre projet Supabase est actif
2. Confirmez l'URL dans le dashboard Supabase
3. Testez avec curl : curl -I https://[PROJECT-ID].supabase.co
4. Essayez le Transaction Pooler si Direct Connection Ã©choue
```

**ProblÃ¨me** : `prepared statement already exists`
```bash
# Solution : Ajoutez statement_cache_size=0 
conn = await asyncpg.connect(database_url, statement_cache_size=0)
```

### âŒ Extensions PostgreSQL

**pgvector manquant** :
```bash
# Dans Supabase Dashboard :
Settings > Database > Extensions > Rechercher "pgvector" > Enable
```

**uuid-ossp manquant** :
```sql
-- GÃ©nÃ©ralement prÃ©-installÃ©, sinon :
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
```

### âŒ ProblÃ¨mes Python

**psycopg2 compilation** :
```bash
# Utilisez la version binary :
pip uninstall psycopg2
pip install psycopg2-binary
```

**Version Python** :
```bash
# VÃ©rifiez la version :
python --version  # Doit Ãªtre 3.11+

# Si trop ancienne, installez Python 3.11+ :
# macOS : brew install python@3.11
# Ubuntu : sudo apt install python3.11
# Windows : TÃ©lÃ©chargez depuis python.org
```

### âŒ Redis Connection

**Redis local indisponible** :
```bash
# Option 1 : Docker
docker-compose up -d redis

# Option 2 : Installation locale
# macOS : brew install redis && brew services start redis
# Ubuntu : sudo apt install redis-server

# Option 3 : Redis Cloud
# Upstash, Redis Cloud, ou autre service
REDIS_URL=redis://username:password@host:port/0
```

### âŒ Permissions et AccÃ¨s

**Erreur Supabase permissions** :
```bash
# VÃ©rifiez les Row Level Security (RLS) dans Supabase
# Si activÃ©, ajoutez des policies ou utilisez service_role_key
```

## ï¿½ğŸ“Š MÃ©triques de Performance

- **Vitesse de crawl** : 1000+ pages/minute
- **Recherche vectorielle** : <100ms (avec pgvector)
- **DÃ©couverte quotidienne** : 100+ nouvelles sources
- **DÃ©duplication** : 99.9% de prÃ©cision
- **Uptime** : 99.9% (dÃ©pend de Supabase)
- **Latence API** : <50ms moyenne

## ğŸ” SÃ©curitÃ© et Bonnes Pratiques

### ï¿½ï¸ Configuration SÃ©curisÃ©e

```bash
# Production : Utilisez des secrets forts
SECRET_KEY=$(openssl rand -base64 32)

# Supabase : Activez Row Level Security
# Dashboard > Authentication > Settings > Enable RLS

# API Keys : Rotation rÃ©guliÃ¨re
# Dashboard > Settings > API > Regenerate keys

# Monitoring : Logs et alertes
LOG_LEVEL=INFO  # Pas DEBUG en production
```

### ï¿½ Variables Sensibles

**Jamais dans le code** :
- Mots de passe Supabase
- ClÃ©s API OpenAI
- Tokens d'authentification
- Secrets de chiffrement

**Stockage sÃ©curisÃ©** :
- Variables d'environnement
- Gestionnaires de secrets (HashiCorp Vault, AWS Secrets Manager)
- Fichiers .env avec permissions restreintes (`chmod 600 .env`)

## ğŸ“ˆ Scaling et Performance

### ğŸ”„ Horizontal Scaling

```bash
# Workers Celery multiples
celery -A src.celery_app worker --loglevel=info --concurrency=4 --queues=crawler
celery -A src.celery_app worker --loglevel=info --concurrency=2 --queues=discovery
celery -A src.celery_app worker --loglevel=info --concurrency=2 --queues=indexing

# Load balancing API
gunicorn src.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### â¬†ï¸ Vertical Scaling

```bash
# Configuration adaptative
CELERY_WORKER_CONCURRENCY=${CPU_CORES:-4}
DATABASE_POOL_SIZE=${DB_POOL_SIZE:-20}
CRAWLER_MAX_WORKERS=${MAX_WORKERS:-50}

# Monitoring des ressources
top, htop, docker stats
```

### ğŸ¯ Optimisations Supabase

```sql
-- Index pour recherche rapide
CREATE INDEX idx_articles_published ON articles(published_at DESC);
CREATE INDEX idx_articles_category ON articles(category);
CREATE INDEX idx_sources_active ON sources(is_active) WHERE is_active = true;

-- Index vectoriel pour pgvector
CREATE INDEX idx_articles_content_embedding ON articles 
USING ivfflat (content_embedding vector_cosine_ops);
```

## ğŸ› ï¸ DÃ©veloppement et Tests

### ğŸ§ª Tests

```bash
# Tests unitaires
pytest tests/ -v

# Tests d'intÃ©gration
pytest tests/integration/ -v

# Coverage
pytest --cov=src tests/

# Tests de performance
pytest tests/performance/ --benchmark-only
```

### ğŸ” Linting et Format

```bash
# Formatting
black src/ tests/

# Linting
flake8 src/ tests/

# Type checking
mypy src/

# Import sorting
isort src/ tests/
```

### ï¿½ Pre-commit Hooks

```bash
# Installation
pip install pre-commit
pre-commit install

# Hooks configurÃ©s :
# - black (formatting)
# - flake8 (linting)
# - mypy (type checking)
# - tests (unitaires)
```

## ğŸŒ DÃ©ploiement

### ğŸš¢ Docker Production

```dockerfile
# Dockerfile optimisÃ©
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY src/ ./src/
CMD ["gunicorn", "src.main:app", "--workers", "4", "--worker-class", "uvicorn.workers.UvicornWorker", "--bind", "0.0.0.0:8000"]
```

### â˜ï¸ Cloud Deployment

**Recommended Platforms** :
- **Railway** : DÃ©ploiement simple avec Supabase
- **Render** : Auto-deploy depuis Git
- **Fly.io** : Global edge deployment
- **Google Cloud Run** : Serverless containers
- **AWS ECS** : Container orchestration

### ğŸ”„ CI/CD Pipeline

```yaml
# .github/workflows/deploy.yml
name: Deploy
on:
  push:
    branches: [main]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run tests
        run: |
          pip install -r requirements.txt
          pytest
  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to production
        run: |
          # Votre logique de dÃ©ploiement
```

## ï¿½ Documentation et Support

### ğŸ“– Documentation DÃ©taillÃ©e

- [ğŸ—ï¸ Architecture](docs/architecture.md) - Design et composants
- [ğŸš€ DÃ©ploiement](docs/deployment.md) - Guide de production
- [ğŸ“¡ API Reference](docs/api.md) - Endpoints et schemas
- [ğŸ“Š Monitoring](docs/monitoring.md) - MÃ©triques et alertes
- [ğŸ”§ Contribution](docs/contributing.md) - Guide dÃ©veloppeurs

### ğŸ¤ Support et CommunautÃ©

- **Issues GitHub** : [Rapporter un bug](link)
- **Discussions** : [Questions et suggestions](link)
- **Wiki** : [Base de connaissances](link)
- **Discord** : [CommunautÃ© temps rÃ©el](link)

### ğŸ”„ Roadmap

- [ ] **Q1 2025** : Interface web admin
- [ ] **Q2 2025** : Plugins d'extensions
- [ ] **Q3 2025** : ML avancÃ© (classification)
- [ ] **Q4 2025** : Multi-tenant SaaS

---

## ğŸ† DÃ©veloppÃ© par The-Genium007

**SentinelIQ Harvester** - Veille technique autonome et intelligente ğŸš€

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.11+-green.svg)](https://python.org)
[![Supabase](https://img.shields.io/badge/database-Supabase-green.svg)](https://supabase.com)
[![FastAPI](https://img.shields.io/badge/api-FastAPI-teal.svg)](https://fastapi.tiangolo.com)
